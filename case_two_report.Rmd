---
title: "Case Two Report"
authors: "Bob Ding, Cathy Lee, Malavi Ravindran"
output: pdf_document
---

RUNTIME: 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Call Libraries
```{r}
library(zoo)
library(varian)
library(tidyverse)
library(corrplot)
library(glmnet)
library(FactoMineR)
library(factoextra)
library(MASS)
library(caret)
library(MLmetrics)
library(pROC)
library(gridExtra)
library(grid)
library(broom)
library(knitr)
```


```{r}
library(sjPlot)
library(RColorBrewer)
library(kableExtra)
```

# I. Introduction

# II a. Data

# Create Data and Feature Engineering

```{r calc-stats-features}
features_all_modalities = function(fn, win_size, shift) {
  df_all = read.csv(fn) %>%
    mutate(ACC_chest_3D = sqrt(ACC_chest_X^2+ACC_chest_Y^2+ACC_chest_Z^2)) %>%
    mutate(ACC_wrist_3D = sqrt(ACC_wrist_x^2+ACC_wrist_y^2+ACC_wrist_z^2))
  drops <- c("X", "Label", "subject")
  df = df_all[ , !(names(df_all) %in% drops)]
  replace_rows =  length(rollapply(df[,1], width = win_size*4, by = shift, FUN = mean, align = "left"))
  features_df <- data.frame(matrix(ncol = ncol(df)*4, nrow = replace_rows))
  new_names = sapply(1:length(df), function(c) {
    c(paste0(colnames(df)[c],"_mean"),
      paste0(colnames(df)[c],"_sd"),
      #paste0(colnames(df)[c],"_range"),
      paste0(colnames(df)[c],"_min"),
      paste0(colnames(df)[c],"_max")
      # paste0(colnames(df)[c],"_skew")
      )
  })
  colnames(features_df) = new_names



  for (c in 1:length(df)) {

    # finding mu
    mu_vals = rollapply(df[,c], width = win_size*4, by = shift, FUN = mean, align = "left")
    new_col_name = paste0(colnames(df)[c],"_mean")
    cindx = which(colnames(features_df)==new_col_name)
    features_df[, cindx] = mu_vals

    # finding sd
    sd_vals = rollapply(df[,c], width = win_size*4, by = shift, FUN = var, align = "left")
    new_col_name = paste0(colnames(df)[c],"_sd")
    cindx = which(colnames(features_df)==new_col_name)
    features_df[, cindx] = sqrt(sd_vals)

    # finding max
    max_vals = rollapply(df[,c], width = win_size*4, by = shift, FUN = max, align = "left")
    new_col_name = paste0(colnames(df)[c],"_max")
    cindx = which(colnames(features_df)==new_col_name)
    features_df[, cindx] = max_vals

    # finding min
    min_vals = rollapply(df[,c], width = win_size*4, by = shift, FUN = min, align = "left")
    new_col_name = paste0(colnames(df)[c],"_min")
    cindx = which(colnames(features_df)==new_col_name)
    features_df[, cindx] = min_vals

  }

 # make sure merge label, subject back into feature dataframe
  features_df$Label = df_all[1:replace_rows, "Label"]
  features_df$Subject = df_all[1:replace_rows, "subject"]
  return(features_df)
}
```

```{r hr-calc}
HR_calc = function(df, win_size, shift) {
  df <- df[rep(seq_len(nrow(df)), each = 4), ]
  mu_vals = rollapply(df, width = win_size*4, by = shift, FUN = mean, align = "left")
  sd_vals = rollapply(df, width = win_size*4, by = shift, FUN = sd, align = "left")
  min_vals = rollapply(df, width = win_size*4, by = shift, FUN = min, align = "left")
  max_vals = rollapply(df, width = win_size*4, by = shift, FUN = max, align = "left")

  return(list(mu = mu_vals, sd = sd_vals,
              min = min_vals, max = max_vals))
}
```

```{r import-file-names}
file_list <- list.files()
subject_data = file_list[grepl("df_S", file_list, fixed = TRUE)]
```

```{r run-all-featengine-combine }
ALL_df = NULL
for (i in 1:length(subject_data)) {
  print(i)
  feature_data = features_all_modalities(subject_data[i], 5, 1) #CHANGE FILE PATH 
  subject_no = gsub("\\..*","", sub('.*_', '', subject_data[i]))
  HR_fn = paste0("~/case-study-2/WESAD/", subject_no, "/", subject_no, "_E4_Data/HR.csv") #CHANGE FILEPATH to be : paste0("/hpc/group/sta440-f20/WESAD/WESAD/", subject_no, "/" )
  HR_data = read.csv(HR_fn)[-1,]
  hr = HR_calc(as.data.frame(HR_data), 5, 1)

  df_hr = data.frame(matrix(unlist(hr), nrow= length(hr$mu),
                             ncol=4, byrow = F))
  colnames(df_hr) = c("hr_wrist_mu","hr_wrist_sd", "hr_wrist_min", "hr_wrist_max")#, "hr_wrist_range")
  df_hr$ID =seq.int(nrow(df_hr))
  
  feature_data = feature_data[-c(1:40),]
  feature_data$ID <- seq.int(nrow(feature_data))

  S_df = merge(feature_data, df_hr, by="ID")
  ALL_df = rbind(ALL_df, S_df)
}
ALL_df = ALL_df %>% filter(Label %in% c("2","3"))
write.csv(ALL_df, "master10000_df.csv")
```

# II b. EDA

# EDA

```{r corrplot}
ALL_df = read.csv("master_df.csv", header = T)[,-c(1:2)]

# get rid of chest EDA and temp and all min max (underdispersion)
remove_select_cov = ALL_df %>%
  dplyr::select(-contains("ACC_wrist")) %>%
  dplyr::select(-EDA_mean, -EDA_sd, -EDA_max, -EDA_min) %>%
  dplyr::select(-Temp_mean, -Temp_sd, -Temp_max, -Temp_min) %>%
  dplyr::select(-contains("BVP")) %>%
  dplyr::select(-contains("ECG")) %>%
  dplyr::select(-contains("min")) %>%
  dplyr::select(-contains("max")) %>%
  dplyr::select(-contains("ACC_chest_X_mean")) %>%
  dplyr::select(-contains("ACC_chest_Y_mean")) %>%
  dplyr::select(-contains("ACC_chest_Z_mean")) %>%
  dplyr::select(-contains("ACC_chest_3D_mean")) 

# maybe reorder the variables
col_order <- c("ACC_chest_X_sd", "ACC_chest_Y_sd", "ACC_chest_Z_sd", "ACC_chest_3D_sd", "EMG_mean", "EMG_sd", "Resp_mean", "Resp_sd", "EDA_wrist_mean", "EDA_wrist_sd", "TEMP_wrist_mean", "TEMP_wrist_sd",  "hr_wrist_mu", "hr_wrist_sd", "Subject", "Label")
remove_select_cov <- remove_select_cov[, col_order]

remove_select_cov$Subject <- factor(remove_select_cov$Subject, levels = c("S2", "S3","S4", "S5","S6", "S7","S8", "S9","S10", "S11","S13", "S14","S15", "S16","S17"))

remove_select_cov$Label <- ifelse(remove_select_cov$Label=="2", 1, 0)

non_biological = c("Label", "Subject")
remove_select_cov_nb = remove_select_cov[ , !(names(remove_select_cov) %in% non_biological)]

cormatrix = cor(remove_select_cov_nb)
corrplot::corrplot(cormatrix, method="color", addCoef.col="black", tl.cex = 0.4, number.cex= 10/ncol(remove_select_cov_nb),  title="Fig. 1 Correlation Matrix of Engineered Features", mar=c(0,0,1,0))
```
From the correlation matrix (Fig. 1), we see that the `ACC` variables (variables related to motion) are highly correlated. We also see some moderate correlation between `Resp` and `EDA` variables, as well as between `EDA` and `TEMP` variables.

```{r distrib-vs-label, echo=F, fig.width = 5, fig.height = 10}
p1=ggplot(remove_select_cov, aes(y=EDA_wrist_mean, x=factor(Label), group = factor(Label))) + geom_boxplot() + facet_grid(~Subject) +
    labs(x ="State", y = "Mean EDA (wrist)", title = "Fig. 2 Distribution of Mean Wrist EDA by State for All Subjects")

p2=ggplot(remove_select_cov, aes(y=TEMP_wrist_mean, x=factor(Label), group = factor(Label))) + geom_boxplot() + facet_grid(~Subject) +
    labs(x ="State", y = "Mean Temperature (wrist)", title = "Fig. 3 Distribution of Mean Wrist Temperature by State for All Subjects")

p3=ggplot(remove_select_cov, aes(y=hr_wrist_mu, x=factor(Label), group = factor(Label))) + geom_boxplot() + facet_grid(~Subject) +
    labs(x ="State", y = "Mean Heart Rate (wrist)", title = "Fig. 4 Distribution of Mean Heart Rate by State for All Subjects")

grid.arrange(p1, p2, p3, nrow = 1)
```
After examining boxplots of the distribution of the physiological measures by state for each subject (see Appendix A.1 for all plots of this type), the variables that had the greatest difference in distribution between states and across subjects are `EDA_wrist_mean`, `Temp_wrist_mean`, and `hr_wrist_mu`. For all subjects, mean EDA values (Fig. 2) are higher in the stress state, and for subjects 3, 5, 6, 7, 10, 13, the difference in the distribution of EDA between the two states is more drastic then that of the other subjects. For `Temp_wrist_mean` (Fig. 3), we can see that for some subjects, their mean temperature tends to be higher in the stress state but for others, their mean temperatue tends to be lower when stressed. Likewise, for `hr_wrist_mu` (Fig. 4), we see that some subjects have higher average heart rate when stressed while others exhibit the opposite behavior. Among all of the other variables, it appears that the motion (`ACC`)  variables tend to show a higher distribtion for each subject under the stress state, and the `EMG` and `Resp` variables tend not to vary much in distribution between states across subjects. 

# III. Methods

# Wrist Data Cleaning

```{r wristcorrplot,  echo=F, fig.width = 5, fig.height = 5}
#ALL_df = read.csv("master_df.csv", header = T)[,-c(1:2)]
wrist_only = ALL_df %>%
  dplyr::select(contains("wrist")) %>%
  dplyr::select(-contains("ACC_wrist_x_mean")) %>%
  dplyr::select(-contains("ACC_wrist_y_mean")) %>%
  dplyr::select(-contains("ACC_wrist_z_mean")) %>%
  dplyr::select(-contains("ACC_wrist_3D_mean"))

wrist_only = cbind(wrist_only, as.data.frame(ALL_df$Subject), as.data.frame(ALL_df$Label))
wrist_only = wrist_only %>%
  rename(Subject = `ALL_df$Subject`) %>%
  rename(Label = `ALL_df$Label`) %>%
  mutate(Label = ifelse(Label==2, 1, 0))# %>%
  dplyr::select(-contains("min")) %>%
  dplyr::select(-contains("max"))


# maybe reorder the variables
col_order <- c("ACC_wrist_x_sd", "ACC_wrist_y_sd",   "ACC_wrist_z_sd",  "ACC_wrist_3D_sd", "EDA_wrist_mean", "EDA_wrist_sd", "TEMP_wrist_mean", "TEMP_wrist_sd",  "hr_wrist_mu", "hr_wrist_sd", "Subject", "Label")
wrist_only <- wrist_only[, col_order]

wrist_only$Subject <- factor(wrist_only$Subject, levels = c("S2", "S3","S4", "S5","S6", "S7","S8", "S9","S10", "S11","S13", "S14","S15", "S16","S17"))

non_biological = c("Label", "Subject")
wrist_nb = wrist_only[ , !(names(wrist_only) %in% non_biological)]

# maybe reorder the variables
cormatrix = cor(wrist_nb)
corrplot::corrplot(cormatrix, method = "color", addCoef.col="black", tl.cex = 0.6, number.cex= 8/ncol(wrist_nb), title="Fig. 5 Correlation Matrix of Engineered Features (Wrist Only)", mar=c(0,0,1,0))
```
For the wrist only data, we see similar correlation structures as before (with all of the data). Motion variables are strongly correlated with each other, and there is some correlation between `EDA` and `TEMP` variables.

# Wrist PCA

```{r pca}
scaled_wrist_nb = scale(wrist_nb, center = TRUE, scale = TRUE)
res.pca <- PCA(scaled_wrist_nb, graph = FALSE, ncp = 4)
eig.val <- get_eigenvalue(res.pca)
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r pca-cont,  echo=F, fig.width = 5, fig.height =5}
var <- get_pca_var(res.pca)
corrplot::corrplot(var$cos2, is.corr=FALSE, tl.cex = 0.5, number.cex= 3/ncol(remove_select_cov_nb), title = "Fig. 6 Quality of Representation Plot for Wrist PCA", mar=c(0,0,1,0))

fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 4, top = 10)
```
In the quality of representation plot above (Fig. 6 shows the importance of a principal component for a given observation), we can see that the principal components (with number of components being 4) are about variability in motion, dermal temperature and activity, heart rate, and variability in temperature.

```{r}
wrist_pca_vals <- as.data.frame(res.pca$ind$coord)
wrist_pca_vals$Label = wrist_only$Label
wrist_pca_vals$Subject = wrist_only$Subject
```

# Wrist Model

```{r run-wrist-model}
wrist_only_nsubj = wrist_only %>% dplyr::select(-Subject, -Label)
scaled_wrist_only = scale(wrist_only_nsubj, center=TRUE, scale = FALSE)
scaled_wrist_only = cbind(scaled_wrist_only, as.data.frame(wrist_only$Subject), as.data.frame(wrist_only$Label))
scaled_wrist_only = scaled_wrist_only %>%
  rename(Subject = `wrist_only$Subject`) %>%
  rename(Label = `wrist_only$Label`)

smp_size <- floor(0.75 * nrow(scaled_wrist_only))
train_ind <- sample(seq_len(nrow(scaled_wrist_only)), size = smp_size)
train_wrist <- scaled_wrist_only[train_ind, ]
test_wrist <- scaled_wrist_only[-train_ind, ]

# OUR MODEL FOR WRIST
wrist.full = glm(Label ~. -Subject, family = "binomial", data = train_wrist)
# summary(wrist.full)
# 
# pred.test = wrist.full %>% predict(test_wrist, type= "response")
# pred.test = ifelse(pred.test>0.5, 1,0)
# 
# mean(test_wrist$Label==pred.test)
```

```{r wrist-stepwise-glmnet}
# stepwise
step.wrist.model = wrist.full %>% stepAIC(trace=FALSE)
summary(step.wrist.model)

#convert training data to matrix format
train_wrist_x = train_wrist %>% 
  dplyr::select(-Label) %>%
  mutate(Subject = as.factor(Subject))

x <- data.matrix(train_wrist_x)
y <- train_wrist$Label
lasso.fit = glmnet(x, y, alpha = 1, family = "binomial")
plot(lasso.fit)
elasticnet.fit = glmnet(x, y, alpha = 0.5, family = "binomial")
plot(elasticnet.fit)
```

# Wrist K-Fold CV

```{r wrist-kfold-cv}
# set.seed(123)
# 
# kfoldcv_wrist_full = function(df) {
#   
#   actual_values = c()
#   predicted_values = c()
#   fitted_probs = c()
#   
#   # fold_accuracies = c()
#   # fold_f1 = c()
#   
#   fold_no = c()
#   subject = c()
#   
#   print("at folds")
#   folds <- createFolds(factor(df$Subject), k = 5)
#   
#   print("past folds")
#   for (i in 1:5) {
#   #train and test
#     col = paste0("Fold", i)
#     indx = unlist(folds[col])
# 
#   train<- df[-indx,]
#   print(nrow(train))
#   test<- df[indx, ]
#   print(nrow(test))
#   
#   
#   # run model
#   wrist.full = glm(Label ~. -Subject, family = "binomial", data = train)
# #summary(wrist.full)
# 
# pred.test = wrist.full %>% predict(test, type= "response")
# fitted_probs = c(fitted_probs, pred.test)
# pred.test = ifelse(pred.test>0.5, 1,0)
# predicted_values = c(predicted_values, pred.test)
# actual_values = c(actual_values, test$Label)
# 
# 
#   subject = c(subject, test$Subject)
#   fold_no = c(fold_no, rep(i, nrow(test)))
#   
#   
#   
#   #acc1 = mean(test1$Label==pred.test)
#   #fold_accuracies = c(fold_accuracies, acc1)
#   
#   # add function to compute f1
#   # blah
# }
#   #train on training set
#   #test on testing set 
#   #predict labels
#   #find accuracy and f1, add to fold_accuracies and fold_f1
#   #put predicted values in predicted_values
#   #put actual values in actual_values
#   
#   cvoutput = data.frame(cbind(actual_values, predicted_values, fitted_probs, 
#         fold_no, subject))
#   
#   return(cvoutput)
# }
# 
# wristcvoutput = kfoldcv_wrist_full(scaled_wrist_only)
```

```{r wrist-kfold-res}
# fold1 = wristcvoutput %>%
#   filter(subject=="S11")
# 
# mean(fold1$actual_values==fold1$predicted_value)
```

# Combo PCA

```{r pca-combo}
scaled_select_cov_nb = scale(remove_select_cov_nb, center = TRUE, scale = TRUE)

res.pca <- PCA(scaled_select_cov_nb, graph = FALSE, ncp = 4)
eig.val <- get_eigenvalue(res.pca)
#eig.val
#fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r pca-cont-combo,  echo=F, fig.width = 5, fig.height = 5}
var <- get_pca_var(res.pca)
corrplot::corrplot(var$cos2, is.corr=FALSE, tl.cex = 0.5, number.cex= 3/ncol(remove_select_cov_nb), title = "Fig. 7 Quality of Representation Plot for All Data PCA")

fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 4, top = 10)
#fviz_contrib(res.pca, choice = "var", axes = 5, top = 10)
```
From the plot above (Fig. 7), we see that the principal components are variability in movement (Dim.1), dermal temperature and activity (Dim.2), heart rate (Dim.3), and Neuro-muscular acitivity (Dim.4).

```{r pca-vars-combo}
pca_vals <- as.data.frame(res.pca$ind$coord)
pca_vals$Label = remove_select_cov$Label
pca_vals$Subject = remove_select_cov$Subject
```

# Combo Model

```{r combo-model}
smp_size <- floor(0.75 * nrow(pca_vals))
train_ind <- sample(seq_len(nrow(pca_vals)), size = smp_size)
train_pca <- pca_vals[train_ind, ]
test_pca <- pca_vals[-train_ind, ]

# COMBO PCA MODEL model without Subject  INTERPRET MAIN EFFECTS
pca.model = glm(Label ~ .-Subject, family = binomial(link="logit"), data=train_pca)

# summary(pca.model)
# 
# pred.test = pca.model %>% predict(test_pca, type= "response")
# pred.test = ifelse(pred.test>0.5, 1,0)
# 
# mean(test_pca$Label==pred.test)

est = round(summary(pca.model)$coefficients[,1],2)
SE = round(summary(pca.model)$coefficients[,2],2)
ci = round(confint(pca.model),2)

combo_model_tab = data.frame(cbind(est,SE,ci))
colnames(combo_model_tab) = c("Estimate", "SE", "2.5%", "97.5%")
kable(combo_model_tab, caption = "Estimate and Confidence Intervals for Coefficients in the All Data Model")
```
A increase of one in the standard deviation for movement and dermal temperature and activity is associated with a multiplicative increase in the odds that the state is stress. A increase of one in the standard deviation of heart rate and neuro-muscular activity is associated with a multiplicative decrease in the odds that the state is stress.


```{r combo-stepwise-glmnet}
# stepwise
step.wrist.model = pca.model %>% stepAIC(trace=FALSE)
summary(step.wrist.model)

#convert training data to matrix format
train_pca_x = train_pca %>% 
  dplyr::select(-Label) %>%
  mutate(Subject = as.factor(Subject))

x <- data.matrix(train_pca_x)
y <- train_pca$Label
lasso.fit = glmnet(x, y, alpha = 1, family = "binomial")
plot(lasso.fit)
elasticnet.fit = glmnet(x, y, alpha = 0.5, family = "binomial")
plot(elasticnet.fit)
```

# Combo K-Fold CV

```{r combo-wrist-kfold-cv-nosubj}
set.seed(123)

kfoldcv_no_subject = function(df) {
  
  actual_values = c()
  predicted_values = c()
  fitted_probs = c()
  
  # fold_accuracies = c()
  # fold_f1 = c()
  
  fold_no = c()
  subject = c()
  
  #print("at folds")
  folds <- createFolds(factor(df$Subject), k = 5)
  
  #print("past folds")
  for (i in 1:5) {
  #train and test
    col = paste0("Fold", i)
    indx = unlist(folds[col])

  train<- df[-indx,]
  #print(nrow(train))
  test<- df[indx, ]
  #print(nrow(test))
  
  
  # run model
pca.model = glm(Label ~ .-Subject, family = binomial(link="logit"), data=train)
#summary(wrist.full)

pred.test = pca.model %>% predict(test, type= "response")
fitted_probs = c(fitted_probs, pred.test)
pred.test = ifelse(pred.test>0.5, 1,0)
predicted_values = c(predicted_values, pred.test)
actual_values = c(actual_values, test$Label)


  subject = c(subject, test$Subject)
  fold_no = c(fold_no, rep(i, nrow(test)))
  
  
  
  #acc1 = mean(test1$Label==pred.test)
  #fold_accuracies = c(fold_accuracies, acc1)
  
  # add function to compute f1
  # blah
}
  #train on training set
  #test on testing set 
  #predict labels
  #find accuracy and f1, add to fold_accuracies and fold_f1
  #put predicted values in predicted_values
  #put actual values in actual_values
  
  cvoutput = data.frame(cbind(actual_values, predicted_values, fitted_probs, 
        fold_no, subject))
  
  return(cvoutput)
}

combocvoutput = kfoldcv_no_subject(pca_vals)
wristcvoutput = kfoldcv_no_subject(wrist_pca_vals)
```

```{r combo-kfold-res}
combo_acc_per_fold = combocvoutput %>%
  group_by(fold_no) %>%
  summarize(accuracy = mean(actual_values==predicted_values))

combo_f1_per_fold = combocvoutput %>%
  group_by(fold_no) %>%
  summarize(f1 = F1_Score(actual_values, predicted_values, positive = NULL)) 

wrist_acc_per_fold = wristcvoutput %>%
  group_by(fold_no) %>%
  summarize(accuracy = mean(actual_values==predicted_values))

wrist_f1_per_fold = wristcvoutput %>%
  group_by(fold_no) %>%
  summarize(f1 = F1_Score(actual_values, predicted_values, positive = NULL)) 

# REWMEMEVR TO ROUDN
acc_f1_data <- matrix(c(round(mean(combo_acc_per_fold$accuracy),2),
                  round(mean(wrist_acc_per_fold$accuracy),2),
                  round(mean(combo_f1_per_fold$f1),2),
                  round(mean(wrist_f1_per_fold$f1),2)),ncol=2,byrow=TRUE)
colnames(acc_f1_data) <- c("All","Wrist")
rownames(acc_f1_data) <- c("Accuracy","F1")
acc_f1_tab <- as.table(acc_f1_data)
kable(acc_f1_tab, caption = "Accuracy and F1 for All Data and Wrist Models")
```

```{r}
# add row and col names or get rid of kable
combo_cm = as.table(confusionMatrix(as.factor(combocvoutput$predicted_values), as.factor(combocvoutput$actual_values)))
colnames(combo_cm) = c("Actual Amusement", "Actual Stress")
rownames(combo_cm) = c("Predicted Amusement", "Predicted Stress")
#kable(combo_cm, caption = "Confusion Matrix for All Data Model")

wrist_cm = as.table(confusionMatrix(as.factor(wristcvoutput$predicted_values), as.factor(wristcvoutput$actual_values)))
colnames(wrist_cm) = c("Actual Amusement", "Actual Stress")
rownames(wrist_cm) = c("Predicted Amusement", "Predicted Stress")
#kable(wrist_cm, caption = "Confusion Matrix for Wrist Data Model")

# kable(wrist_cm) %>%
#   kable_styling(full_width = FALSE, position = "float_left",
#                 title = "Confusion Matrix for All Data Model")
# kable(combo_cm) %>%
#   kable_styling(full_width = FALSE, position = "left",
#                 title = "Confusion Matrix for Wrist Data Model")

knitr::kable(list(combo_cm, wrist_cm), caption = "Confusion Matrices for All Data (left) and Wrist (right) Models")

```
In Table 1 (and in the confusion matrices Table 2), we see the average accuracy and F1 results of 5-folds cross validation for a model using only wrist data and a model using both chest and wrist data. The model using both types of sensor data has higher accuracy and F1. 

# IV. Results

# Final Model

```{r, warning = F}
# HOPEFULLY THE RIGHT ONE model with no main effect for Subject but with interactions
pca.model.interact = glm(Label ~ Dim.1+Dim.2+Dim.3+Dim.4+Dim.1:Subject
                  +Dim.2:Subject
                  +Dim.3:Subject
                  +Dim.4:Subject
                 , family = binomial(link="logit"), data=pca_vals)

summary(pca.model.interact)

pred.test = pca.model.interact %>% predict(pca_vals, type= "response")
pca_vals$fitted = pred.test
pred.test = ifelse(pred.test>0.5, 1,0)
pca_vals$predicted = pred.test

# 
# mean(test_pca$Label==pred.test)
# 
# F1_Score(test_pca$Label, pred.test, positive = NULL)
# confusionMatrix(as.factor(pred.test), as.factor(test_pca$Label))
```

```{r combo-kfold-cv, warning = F}
set.seed(123)

kfoldcv_final = function(df) {
  
  actual_values = c()
  predicted_values = c()
  fitted_probs = c()
  
  # fold_accuracies = c()
  # fold_f1 = c()
  
  fold_no = c()
  subject = c()
  
  print("at folds")
  folds <- createFolds(factor(df$Subject), k = 5)
  
  print("past folds")
  for (i in 1:5) {
  #train and test
    col = paste0("Fold", i)
    indx = unlist(folds[col])

  train<- df[-indx,]
  print(nrow(train))
  test<- df[indx, ]
  print(nrow(test))
  
  
  # run model
pca.model.interact = glm(Label ~ Dim.1+Dim.2+Dim.3+Dim.4+Dim.1:Subject
                  +Dim.2:Subject
                  +Dim.3:Subject
                  +Dim.4:Subject
                 , family = binomial(link="logit"), data=train)
#summary(wrist.full)

pred.test = pca.model.interact %>% predict(test, type= "response")
fitted_probs = c(fitted_probs, pred.test)
pred.test = ifelse(pred.test>0.5, 1,0)
predicted_values = c(predicted_values, pred.test)
actual_values = c(actual_values, test$Label)


  subject = c(subject, test$Subject)
  fold_no = c(fold_no, rep(i, nrow(test)))
  
  
  
  #acc1 = mean(test1$Label==pred.test)
  #fold_accuracies = c(fold_accuracies, acc1)
  
  # add function to compute f1
  # blah
}
  #train on training set
  #test on testing set 
  #predict labels
  #find accuracy and f1, add to fold_accuracies and fold_f1
  #put predicted values in predicted_values
  #put actual values in actual_values
  
  cvoutput = data.frame(cbind(actual_values, predicted_values, fitted_probs, 
        fold_no, subject))
  
  return(cvoutput)
}

finalcvoutput = kfoldcv_final(pca_vals)
```

```{r final-kfold-res}

#MALAVI ADD FOR SUBJECT

final_acc_per_fold = finalcvoutput %>%
  group_by(fold_no) %>%
  summarize(accuracy = mean(actual_values==predicted_values))

final_f1_per_fold = finalcvoutput %>%
  group_by(fold_no) %>%
  summarize(f1 = F1_Score(actual_values, predicted_values, positive = NULL)) 

final_acc_per_subj = finalcvoutput %>%
  group_by(subject) %>%
  summarize(accuracy = mean(actual_values==predicted_values))

final_f1_per_subj = finalcvoutput %>%
  group_by(subject) %>%
  summarize(f1 = F1_Score(actual_values, predicted_values, positive = NULL)) 

# REWMEMEVR TO ROUDN
# acc_f1_data <- matrix(c(mean(combo_acc_per_fold$accuracy),
#                   mean(wrist_acc_per_fold$accuracy),
#                   "", "",
#                   mean(combo_f1_per_fold$f1),
#                   mean(wrist_f1_per_fold$f1)),ncol=2,byrow=TRUE)
# # colnames(acc_f1_data) <- c("Combo","Wrist")
# # rownames(acc_f1_data) <- c("Accuracy","F1")
# acc_f1_tab <- as.table(acc_f1_data)
# library(broom)
# library(knitr)
# kable(acc_f1_tab, caption = "title")
```

```{r cm-roc-curve,  echo=F, fig.width = 5, fig.height = 5}
final_cm = as.table(confusionMatrix(as.factor(finalcvoutput$predicted_values), as.factor(finalcvoutput$actual_values)))
colnames(final_cm) = c("Actual Amusement", "Actual Stress")
rownames(final_cm) = c("Predicted Amusement", "Predicted Stress")
kable(wrist_cm, caption = "Confusion Matrix for Final  Model")

roc_object = roc(as.numeric(finalcvoutput$actual_values), as.numeric(finalcvoutput$predicted_values, direction="<"))
plot(roc_object,
     col="black", lwd=3, main="Fig. 8 ROC Plot for Final Model")
```
The ROC curve (Fig. 8) shows that our final model (using both chest and wrist data and including interactions for Subject) discriminates moderately well between the stress and amusement states. Specifically, the area under the curve is `r auc(roc_object)`.


# Interaction Plot

```{r}
# ggplot(data = pca_vals %>% filter(Subject %in% c("S4", "S9", "S13", "S17")), aes(x = Dim.1, y = predicted, color = as.factor(Subject))) +
#   #geom_point() +
#   geom_jitter(width = 0.2, height = 0.1, size = 0.3) +
#   #geom_smooth(method = 'glm', method.args = list(family = 'binomial'), 
#  #             size = 2, se = F, aes(color = as.factor(Subject))) +
#   geom_smooth(method = 'glm', method.args = list(family = 'binomial'), 
#               size = 0.5, se = F, fullrange = T, aes(color = as.factor(Subject))) +
#   #geom_dl(aes(label = Subject), method = list(dl.combine("first.points", "last.points")))+
#   labs(color = "Subject", y = "Pr(Amusement State)") +
#   ylim(0,1)
# 
# ggplot(data = pca_vals , aes(x = Dim.1, y = predicted, color = as.factor(Subject))) +
#   #geom_point() +
#   geom_jitter(width = 0.2, height = 0.1, size = 0.3) +
#   #geom_smooth(method = 'glm', method.args = list(family = 'binomial'), 
#  #             size = 2, se = F, aes(color = as.factor(Subject))) +
#   geom_smooth(method = 'glm', method.args = list(family = 'binomial'), 
#               size = 0.5, se = F, fullrange = T, aes(color = as.factor(Subject))) +
#   geom_dl(aes(label = Subject), method = list(dl.combine("first.points", "last.points")))+
#   labs(color = "Subject", y = "Pr(Amusement State)") +
#   ylim(0,1)
```

```{r, echo=F, fig.width = 10, fig.height = 5}
# Define the number of colors you want
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(8, "Set2"))(nb.cols)

p1=plot_model(pca.model.interact, type = "pred", terms = c("Dim.1 [all]", "Subject")) +
  scale_fill_manual(values = mycolors) +  
  scale_y_continuous(name="Fitted Probabilites", limits=c(0, 1)) +
  labs(title = "Fig. 9 Marginal Effects of Motion")

p2=plot_model(pca.model.interact, type = "pred", terms = c("Dim.2 [all]", "Subject")) +
  scale_fill_manual(values = mycolors)  +
  scale_y_continuous(name="Fitted Probabilites", limits=c(0, 1)) +
  labs(title = "Fig. 10 Marginal Effects of Dermal Temperature and Activity")
grid.arrange(p1, p2, nrow = 1)
```
As the variation in motion increases, the fitted probabilities (where stress is 1) increases similarly for all subjects except for S13 and S2. We note for S13 and S2 that as the variability of motion becomes gerater, the fitted probability of stress changes increase by a smaller amount. However, all subject exhibit a similar increasing trend. This behavior can be corroborated by Table [][][] in Appendix [][][]. As the variation in mean dermal temperature and activity increases, the fitted probabilities (where stress is 1) increases similarly for all subjects except for S2, S7, and S13. For these three subjects, the fitted probabilities decrease This behavior can be corroborated by Table [][][] in Appendix [][][].

```{r int-3-4, fig.width = 10, fig.height = 5}
p3 = plot_model(pca.model.interact, type = "pred", terms = c("Dim.3 [all]", "Subject")) +
  scale_fill_manual(values = mycolors)  +
  scale_y_continuous(name="Fitted Probabilites", limits=c(0, 1)) +
  labs(title = "Fig. 11 Marginal Effects of Heart Rate")
p4 = plot_model(pca.model.interact, type = "pred", terms = c("Dim.4 [all]", "Subject")) +
  scale_fill_manual(values = mycolors)  +
  scale_y_continuous(name="Fitted Probabilites", limits=c(0, 1)) +
  labs(title = "Fig. 12 Marginal Effects of Neuro-Muscular Activity")
grid.arrange(p3, p4, nrow = 1)
```
Figure __ shows how as heart rate and variance in heart rate increases, the fitted probabilities of stress decreases similarly for all subjects except for S5, S6, S9, and S17. For these four subjects, the fitted probabilities increase. This behavior can be corroborated by Table [][][] in Appendix [][][], which show positive coefficients for the interaction between subject and the third principal component for these subjects. This positive cofficient indicates that, for these subjects, as heart rate and variance in heart rate increases, the odds of being stressed increase. Though the remaining subjects exhibit a seemingly "unnatural" trend, with the probability of stress *decreasing* with an increased heart rate, research has found that anxiety can be linked to a slowing heart rate as well.

Figure __ shows how as neurological and muscular activity increase, the fitted probabilities of stress decrease similarly for all subjects barring S2, S6, S7, S10, and s14.For these five subjects, the fitted probabilities increase. As can be seen in Table ___ in Appendix ___, the coefficients for the interaction term between subject and the fourth principal component are positive for these subjects. For these individuals, as neuro-muscular activities, such as breathing, increasem the odds of being stressed increase as well. 



# Appendix

## A.1
```{r var-label-subject-plot}
varvslab<- function(var) {
  ggplot(remove_select_cov, aes_(y=as.name(var), x=factor(remove_select_cov$Label), group = factor(remove_select_cov$Label))) + geom_boxplot() + facet_grid(~remove_select_cov$Subject) +
    labs(x ="State", y = as.name(var))
}
do.call(grid.arrange, lapply(names(remove_select_cov_nb), varvslab))
```

## A.2
```{r}
minmax<- function(var) {
  ggplot(min_max_col, aes_(y=as.name(var))) + geom_boxplot() +
    labs(x ="State", y = as.name(var))
}

p=lapply(c("hr_wrist_max", "ACC_chest_Y_max", "ACC_chest_3D_min", "EMG_min"), minmax)
do.call(grid.arrange, p)
```

# Extra Functions
```{r rmssd-calc}
# IBI_data_3 = read.csv("~/case-study-2/WESAD/S3/S3_E4_Data/IBI.csv")
# 
# RMSSD_calc = function(df, peaks) {
#   # for (i in 1:nrow(df)) {
#   #   if (i <= nrow(df)-peaks)
#   vals = rollapply(df[,2], width = peaks, by = 1, FUN = rmssd, align = "left")
#   #}
#   
#   return(vals)
# }
# 
# hrv = RMSSD_calc(IBI_data_3, 3)
# IBI_data_3[1:length(hrv),3] = hrv
# colnames(IBI_data_3)[3] = "HRV"
# IBI_data_3 = na.omit(IBI_data_3)
```

```{r hrv-to-hz}
# hz_format = function(df, win_size) {
#   mu_vals = NULL
#   sd_vals = NULL
#   
#   for (i in 1:nrow(df)) {
#     #if (i <= nrow(df)-win_size)
#     nexttime = df[i,1] + win_size
#       # browser()
#     
#     #print(nexttime)
#     if (i+1 <= nrow(df)) {
# 
#     for (j in i+1:nrow(df)) {
#            # print(df[j,1])
#       if (!is.na(df[j,1])) {
#       #   print(df[j,1]==nexttime)
#       # if (df[j,1]==nexttime) {
#       #   stoprow = j
#       # }
#         # print(i)
#         # print(j)
#         # print(df[j,1])
#         # print(nexttime)
#       if ((df[j,1] >= nexttime) & (df[j-1,1]<nexttime)) {
#         stoprow = j-1
#       }
#       }
#     }
#     mu_vals = c(mu_vals, mean(df[i:stoprow, 3]))
#     sd_vals = c(sd_vals, sqrt(var(df[i:stoprow, 3])))
#     
#     }
#   }
#   
#   return(list(hrv_mu = mu_vals, hrv_sd = sd_vals))
# }

# test = hz_format(IBI_data_3, 5)
```
