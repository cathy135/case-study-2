---
title: "case_study_two"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Call Libraries
```{r}
library(zoo)
library(varian)
library(tidyverse)
library(corrplot)
library(glmnet)
library(FactoMineR)
```

## Import Data

```{r import-file-names}
file_list <- list.files()
subject_data = file_list[grepl("df_S", file_list, fixed = TRUE)]
```

```{r}
# features_all_modalities = function(fn, win_size) {
#   df = read.csv(fn)
#   df = df[,-c("Label", "Subject")]
#   features_df <- data.frame(matrix(ncol = ncol(df)*6, nrow = nrow(df)))
#   new_names = sapply(1:length(df), function(x) {
#     c(paste0(colnames(df[,c]),"_mean"),
#       paste0(colnames(df[,c]),"_sd"),
#       paste0(colnames(df[,c]),"_range"),
#       paste0(colnames(df[,c]),"_min"),
#       paste0(colnames(df[,c]),"_max"),
#       paste0(colnames(df[,c]),"_skew")
#       )
#   })
#   colnames(features_df) = new_names
#   for (r in 1:nrow(df)) {
#     window = df[r:r+win_size*4,]
#     for (c in 1:length(window) ) {
#       if (colnames(window[,c]) != "Label" & colnames(window[,c]) != "Subject") {
#            column = window[,c]
#            
#            mu_column = mean(column)
# 
#            new_col_name = paste0(colnames(window[,c]),"_mean")
#            cindx = colnames(features_df)[whichcolnames(features_df)==new_col_name]
#            features_df[r, cindx] = mu_column
#       }
#     }
#  #make sure merge label subject back into feature dataframe
#   }
#   i
# }
```


```{r calc-stats-features}
features_all_modalities = function(fn, win_size) {
  df_all = read.csv(fn) %>%
    mutate(ACC_chest_3D = ACC_chest_X+ACC_chest_Y+ACC_chest_Z) %>%
    mutate(ACC_wrist_3D = ACC_wrist_x+ACC_wrist_y+ACC_wrist_z)
  drops <- c("X", "Label", "subject")
  df = df_all[ , !(names(df_all) %in% drops)]
  replace_rows =  length(rollapply(df[,1], width = win_size*4, by = 1, FUN = mean, align = "left"))
  features_df <- data.frame(matrix(ncol = ncol(df)*4, nrow = replace_rows))
  new_names = sapply(1:length(df), function(c) {
    c(paste0(colnames(df)[c],"_mean"),
      paste0(colnames(df)[c],"_sd"),
      #paste0(colnames(df)[c],"_range"),
      paste0(colnames(df)[c],"_min"),
      paste0(colnames(df)[c],"_max")
      # paste0(colnames(df)[c],"_skew")
      )
  })
  colnames(features_df) = new_names
  

  
  for (c in 1:length(df)) {
    
    # finding mu
    mu_vals = rollapply(df[,c], width = win_size*4, by = 1, FUN = mean, align = "left")
    new_col_name = paste0(colnames(df)[c],"_mean")
    cindx = which(colnames(features_df)==new_col_name)
    features_df[, cindx] = mu_vals
    
    # finding sd
    sd_vals = rollapply(df[,c], width = win_size*4, by = 1, FUN = var, align = "left")
    new_col_name = paste0(colnames(df)[c],"_sd")
    cindx = which(colnames(features_df)==new_col_name)
    features_df[, cindx] = sqrt(sd_vals)
    
    # finding max
    max_vals = rollapply(df[,c], width = win_size*4, by = 1, FUN = max, align = "left")
    new_col_name = paste0(colnames(df)[c],"_max")
    cindx = which(colnames(features_df)==new_col_name)
    features_df[, cindx] = max_vals
    
    # finding min
    min_vals = rollapply(df[,c], width = win_size*4, by = 1, FUN = min, align = "left")
    new_col_name = paste0(colnames(df)[c],"_min")
    cindx = which(colnames(features_df)==new_col_name)
    features_df[, cindx] = min_vals
    
  }
  
 # make sure merge label, subject back into feature dataframe
  features_df$Label = df_all[1:replace_rows, "Label"]
  features_df$Subject = df_all[1:replace_rows, "subject"]
  return(features_df)
}
```

    

```{r IBI-to-hrv}
# IBI_data_3 = read.csv("~/case-study-2/WESAD/S3/S3_E4_Data/IBI.csv")
# 
# RMSSD_calc = function(df, peaks) {
#   # for (i in 1:nrow(df)) {
#   #   if (i <= nrow(df)-peaks)
#   vals = rollapply(df[,2], width = peaks, by = 1, FUN = rmssd, align = "left")
#   #}
#   
#   return(vals)
# }
# 
# hrv = RMSSD_calc(IBI_data_3, 3)
# IBI_data_3[1:length(hrv),3] = hrv
# colnames(IBI_data_3)[3] = "HRV"
# IBI_data_3 = na.omit(IBI_data_3)
```

```{r hrv-to-hz}
# hz_format = function(df, win_size) {
#   mu_vals = NULL
#   sd_vals = NULL
#   
#   for (i in 1:nrow(df)) {
#     #if (i <= nrow(df)-win_size)
#     nexttime = df[i,1] + win_size
#       # browser()
#     
#     #print(nexttime)
#     if (i+1 <= nrow(df)) {
# 
#     for (j in i+1:nrow(df)) {
#            # print(df[j,1])
#       if (!is.na(df[j,1])) {
#       #   print(df[j,1]==nexttime)
#       # if (df[j,1]==nexttime) {
#       #   stoprow = j
#       # }
#         # print(i)
#         # print(j)
#         # print(df[j,1])
#         # print(nexttime)
#       if ((df[j,1] >= nexttime) & (df[j-1,1]<nexttime)) {
#         stoprow = j-1
#       }
#       }
#     }
#     mu_vals = c(mu_vals, mean(df[i:stoprow, 3]))
#     sd_vals = c(sd_vals, sqrt(var(df[i:stoprow, 3])))
#     
#     }
#   }
#   
#   return(list(hrv_mu = mu_vals, hrv_sd = sd_vals))
# }

# test = hz_format(IBI_data_3, 5)
```

```{r hr-calc}
HR_calc = function(df, win_size) {
  df <- df[rep(seq_len(nrow(df)), each = 4), ]
  mu_vals = rollapply(df, width = win_size*4, by = 1, FUN = mean, align = "left")
  sd_vals = rollapply(df, width = win_size*4, by = 1, FUN = sd, align = "left")
  min_vals = rollapply(df, width = win_size*4, by = 1, FUN = min, align = "left")
  max_vals = rollapply(df, width = win_size*4, by = 1, FUN = max, align = "left")

  return(list(mu = mu_vals, sd = sd_vals,
              min = min_vals, max = max_vals))
}
```

```{r run-all-featengine-combine }
ALL_df = NULL
for (i in 1:length(subject_data)) {
  feature_data = features_all_modalities(subject_data[i], 5) #CHANGE FILE PATH 
  subject_no = gsub("\\..*","", sub('.*_', '', subject_data[i]))
  HR_fn = paste0("~/case-study-2/WESAD/", subject_no, "/", subject_no, "_E4_Data/HR.csv") #CHANGE FILEPATH to be : paste0("/hpc/group/sta440-f20/WESAD/WESAD/", subject_no, "/" )
  HR_data = read.csv(HR_fn)[-1,]
  hr = HR_calc(as.data.frame(HR_data), 5)

  df_hr = data.frame(matrix(unlist(hr), nrow= length(hr$mu),
                             ncol=4, byrow = F))
  colnames(df_hr) = c("hr_wrist_mu","hr_wrist_sd", "hr_wrist_min", "hr_wrist_max")#, "hr_wrist_range")
  df_hr$ID =seq.int(nrow(df_hr))
  
  feature_data = feature_data[-c(1:40),]
  feature_data$ID <- seq.int(nrow(feature_data))

  S_df = merge(feature_data, df_hr, by="ID")
  ALL_df = rbind(ALL_df, S_df)
}
write.csv(ALL_df, "master_df.csv")
```

```{r corrplot}
ALL_df = read.csv("master_df.csv", header = T)[,-c(1:2)]
remove = c("ACC_wrist_x", "ACC_wrist_y","ACC_wrist_z", "ACC_wrist_3D", "EDA_", "TEMP_chest")

remove_select_cov = ALL_df %>%
  select(-contains("ACC_wrist")) %>%
  select(-EDA_mean, -EDA_sd, -EDA_max, -EDA_min) %>%
  select(-Temp_mean, -Temp_sd, -Temp_max, -Temp_min) 


non_biological = c("Label", "Subject")
remove_select_cov_nb = remove_select_cov[ , !(names(remove_select_cov) %in% non_biological)]
remove_select_cov$Label <- ifelse(remove_select_cov$Label=="2", 0, 1)


cormatrix = cor(remove_select_cov_nb)
corrplot(cormatrix, method = "color", addCoef.col="black", tl.cex = 0.4, number.cex= 10/ncol(remove_select_cov_nb))
```

```{r pca}
scaled_biological = scale(remove_select_cov_nb, center = TRUE, scale = TRUE)
res.pca <- PCA(remove_select_cov_nb, graph = FALSE, ncp = 5)
eig.val <- get_eigenvalue(res.pca)
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r pca-cont}
var <- get_pca_var(res.pca)
corrplot(var$cos2, is.corr=FALSE, tl.cex = 0.5, number.cex= 3/ncol(remove_select_cov_nb))

fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 4, top = 10)
fviz_contrib(res.pca, choice = "var", axes = 5, top = 10)
```
PCA basically confirms what we know about the correlations among the variables: we see two components that contains a lot of the ACC variables and another component that combines temperature and electrodermal activity (which makes sense because conditions such as sweating is correlated with temperature). It also makes sense that ECG and respiratory variables would be put with hear rate variables into a component.

```{r distrib-vs-label}
varvslabel <- function(var){
  ggplot(remove_select_cov, aes_(y=as.name(var), x=remove_select_cov$Label, 
                                 group = remove_select_cov$Label)) +
    geom_boxplot() +
    labs(x ="Label", y = as.name(var))
}

lapply(names(remove_select_cov_nb), varvslabel)
```

It appears from these boxplots (prob most all except Electrodermal Activity to appendix), the distribution of physiological measures don't differ much between the stress and amusement states, but the boxplot for EDA shows a difference in distribution.


```{r subject-vs-covariates}
varvssubj <- function(var){
  ggplot(remove_select_cov, aes_(y=as.name(var), x=remove_select_cov$Subject, 
                                 group = remove_select_cov$Subject)) +
    geom_boxplot() +
    labs(x ="Subject", y = as.name(var))
}

lapply(names(remove_select_cov_nb), varvssubj)
```
For ACC, EDA, Temp, and HR variables, the mean, min, max data showed difference in distribution across the subjects. For ECG and BVP variables, only the sd measure showed differences across subjects.

```{r testtrainsplit}
set.seed(123)
smp_size <- floor(0.75 * nrow(remove_select_cov))
train_ind <- sample(seq_len(nrow(remove_select_cov)), size = smp_size)
train <- remove_select_cov[train_ind, ]
# temp = train %>% select(-Label, -Subject)
# temp_centered = data.frame(scale(temp, center=TRUE, scale = FALSE)) 
# temp_centered$Label = train$Label
# train = temp_centered
test <- remove_select_cov[-train_ind, ]
# temp = test %>% select(-Label, -Subject)
# temp_centered = data.frame(scale(temp, center=TRUE, scale = FALSE)) 
# temp_centered$Label = test$Label
# test = temp_centered
```

```{r glmnet-data-driven}
#convert training data to matrix format
x <- as.matrix(train%>%select(-Label), nrow = nrow(train))
#convert class to numerical variable
y <- ifelse(train$Label=="2", 0, 1)
fit = glmnet(x, y, alpha = 1, family = "binomial")

plot(fit)
print(fit)
coefficients = coef(fit, s = 0.057370)

cvfit <- cv.glmnet(x,y,alpha=1,family="binomial",type.measure = "mse")
plot(cvfit)

min = coef(cvfit, s = "lambda.min")
se1 = coef(cvfit, s = "lambda.1se")
```

Now, let's use a domain driven approach.
We know stuff is correlated, so we don't want to use everything

Pick: acc_3D, EDA_min, EDA_max, temp_min, hr_mean, resp_sd
from a physiological standpoint, we know sweat (EDA), heating up (temp), breathing (resp), heart beating (hr),some justofication for ACC makes it seem we should include those in some capcity in our model

```{r domain-driven}
domain.model = glm(Label ~ ACC_chest_3D_mean+ACC_chest_3D_sd+ACC_chest_3D_min+ACC_chest_3D_max+
                   EDA_wrist_mean+EDA_wrist_sd+EDA_wrist_min+EDA_wrist_max+TEMP_wrist_mean+TEMP_wrist_sd+TEMP_wrist_min+TEMP_wrist_max+Resp_mean+Resp_sd+Resp_min+Resp_max+hr_wrist_mu+hr_wrist_sd+hr_wrist_min+hr_wrist_max+Subject
                   , family = binomial(link="logit"), data=train)

#+Subject#+ACC_chest_3D_mean*Subject+
                     # ACC_chest_3D_mean*Subject+
                     # ACC_chest_3D_mean*Subject+
                     # ACC_chest_3D_mean*Subject+

#library(bestglm)
# domain.model = bestglm(Xy = train, family = binomial, IC = "AIC", RequireFullEnumerationQ = T)

# TRY BAS

summary(domain.model)

pred.test = domain.model %>% predict(test, type= "response")
pred.test = ifelse(pred.test>0.5, 1,0)

mean(test$Label==pred.test)

# step.domain.model = domain.model %>% stepAIC(trace=FALSE)
# summary(step.domain.model)

# SUBJECT INCLUDED HERE
full.model = glm(Label ~., family = binomial(link="logit"), data=train)

pred.test = full.model %>% predict(test, type= "response")
pred.test = ifelse(pred.test>0.5, 1,0)

mean(test$Label==pred.test)

# SUBJECT ONLY MODEL
subj.model = glm(Label ~Subject, family = binomial(link="logit"), data=train)

pred.test = subj.model %>% predict(test, type= "response")
pred.test = ifelse(pred.test>0.5, 1,0)

mean(test$Label==pred.test)
```

```{r}
# IBI and HRV and HR

# WORK
# EDA
# # ggpairs
# # pca (Cathy)
# # clusters (Malavi)
# # plot by subject for interactions (Malavi)
# # 0/1 label boxplots versus (Cathy)

# models
# # frequentist Logistic regression w/ interactions
# # stepwise selection/diff selection methods (sensitivity analysis)
# # (DT, Randon Forest. Linear Discriminant Analysis, KNN)
# # for ML (put everything) use feature (variable) importance

# WORK
# # random forest (malavi)
# # Lda/knn (cathy)

# CROSS VALIDATION
# # amy said LOOCV will be computationally expensive
# # start with LOOCV (one person)
```
